{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MphESgi3M7_U"
      },
      "source": [
        "   #RandomSearch with Keras Tuner#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEoAgkn0-EVv"
      },
      "outputs": [],
      "source": [
        "!pip install keras_tuner\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-w6jDKmrMssu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "\n",
        "# Charger le dataset CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normaliser les données (échelle entre 0 et 1)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Encodage one-hot des labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Définition de la fonction pour construire le modèle\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=hp.Choice('filters_1', values=[32, 64, 96]),\n",
        "        kernel_size=hp.Choice('kernel_size_1', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(hp.Choice('dropout_1', values=[0.2, 0.3, 0.4])))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=hp.Choice('filters_2', values=[64, 128]),\n",
        "        kernel_size=hp.Choice('kernel_size_2', values=[3, 5]),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(hp.Choice('dropout_2', values=[0.2, 0.3, 0.4])))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "        units=hp.Choice('dense_units', values=[128, 256, 512]),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(tf.keras.layers.Dropout(hp.Choice('dropout_3', values=[0.3, 0.4, 0.5])))\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))  # 10 classes\n",
        "\n",
        "    # Compiler le modèle\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "        ),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Définir le tuner Keras\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # Nombre d'essais de combinaisons d'hyperparamètres\n",
        "    executions_per_trial=2,  # Nombre d'exécutions par essai pour la robustesse\n",
        "    directory='cifar10_tuning',\n",
        "    project_name='cnn_tuner'\n",
        ")\n",
        "\n",
        "# Recherche des hyperparamètres\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
        ")\n",
        "\n",
        "# Afficher le meilleur hyperparamètre trouvé\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"\"\"\n",
        "Le meilleur nombre de filtres pour la première couche : {best_hps.get('filters_1')}\n",
        "Le meilleur nombre de filtres pour la deuxième couche : {best_hps.get('filters_2')}\n",
        "La meilleure taille de kernel pour la première couche : {best_hps.get('kernel_size_1')}\n",
        "Taux d'apprentissage optimal : {best_hps.get('learning_rate')}\n",
        "\"\"\")\n",
        "\n",
        "# Entraîner le meilleur modèle\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Évaluer le modèle sur les données de test\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtOJ4TuwzoF7"
      },
      "source": [
        "**Simulation de Grid Search with Tuner**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYdLSWEFzzO8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# Charger et préparer les données CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalisation des données\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Encodage one-hot des labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Fonction pour construire le modèle\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # Couche convolutionnelle avec recherche d'hyperparamètres\n",
        "    model.add(Conv2D(\n",
        "        filters=hp.Choice('num_filters', [32, 64]),   # Choix des nombres de filtres\n",
        "        kernel_size=hp.Choice('kernel_size', [3, 5]), # Taille du noyau\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(hp.Choice('dropout_rate', [0.2, 0.4]))) # Taux de dropout\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(hp.Choice('dropout_rate', [0.2, 0.4])))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compilation avec un taux d'apprentissage variable\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [0.001, 0.0001])\n",
        "        ),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialisation du tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy', # Objectif à maximiser\n",
        "    max_trials=16,            # Nombre total de combinaisons (GridSearch simulé)\n",
        "    executions_per_trial=1,   # Répétition des essais pour plus de stabilité\n",
        "    directory='grid_search_tuner',\n",
        "    project_name='cifar10_tuning'\n",
        ")\n",
        "\n",
        "# Définir les données pour la recherche\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    validation_split=0.2,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Afficher les meilleurs hyperparamètres\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\nMeilleurs hyperparamètres :\")\n",
        "print(f\"Nombre de filtres : {best_hps.get('num_filters')}\")\n",
        "print(f\"Taille du noyau : {best_hps.get('kernel_size')}\")\n",
        "print(f\"Taux de dropout : {best_hps.get('dropout_rate')}\")\n",
        "print(f\"Taux d'apprentissage : {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# Entraîner le meilleur modèle\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Évaluation finale sur le jeu de test\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nPrécision finale sur les données de test : {test_acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}